--- 
key: hanspeter 
speaker: Hanspeter Pfister
website: https://vcg.seas.harvard.edu/people/hanspeter-pfister
affiliation: Harvard University
title: Towards Visually Interactive Neural Probabilistic Models
time: 
picture: pfister.jpg
picture-note: Hanspeter Pfister
slides: 
bio: |
    Hanspeter Pfister is the An Wang Professor of Computer Science at the Harvard John A. Paulson School of Engineering and Applied Sciences and an affiliate faculty member of the Center for Brain Science. His research in visual computing lies at the intersection of visualization, computer graphics, and computer vision and spans a wide range of topics, including biomedical image analysis and visualization, image and video analysis, interpretable machine learning, and visual analytics in data science. Pfister has a PhD in computer science from the State University of New York at Stony Brook and an MS in electrical engineering from ETH Zurich, Switzerland. From 2013 to 2017 he was director of the Institute for Applied Computational Science. Before joining Harvard, he worked for over a decade at Mitsubishi Electric Research Laboratories, where he was associate director and senior research scientist. He was the chief architect of VolumePro, Mitsubishi Electric’s award-winning real-time volume rendering graphics card, for which he received the Mitsubishi Electric President’s Award in 2000. Pfister was elected as an ACM Fellow in 2019. He is the recipient of the 2010 IEEE Visualization Technical Achievement Award, the 2009 IEEE Meritorious Service Award, and the 2009 Petra T. Shattuck Excellence in Teaching Award. Pfister is a member of the ACM SIGGRAPH Academy, the IEEE Visualization Academy, and a director of the ACM SIGGRAPH Executive Committee and the IEEE Visualization and Graphics Technical Committee. 
abstract: |
    Deep learning methods have been a tremendously effective approach to problems in computer vision and natural language processing. However, these black-box models can be difficult to deploy in practice as they are known to make unpredictable mistakes that can be hard to analyze and correct. In this talk, I will present collaborative research to develop visually interactive interfaces for probabilistic deep learning models, with the goal of allowing users to examine and correct black-box models through visualizations and interactive inputs. Through co-design of models and visual interfaces, we will take the necessary next steps for model interpretability. Achieving this aim requires active investigation into developing new deep learning models and analysis techniques, and integrating them within interactive visualization frameworks.
---